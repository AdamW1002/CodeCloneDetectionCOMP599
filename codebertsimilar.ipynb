{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "codebertsimilar.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1k0TyXLju0lXFekgkN7jI0yKHpLkiv5C7",
      "authorship_tag": "ABX9TyOpgy3/fKQYhuOLtDNtBaos",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdamW1002/CodeCloneDetectionCOMP599/blob/main/codebertsimilar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0VZBFbTlCR-",
        "outputId": "ae18498c-c2cc-4832-e4e0-05bad923b308"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.17.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from datetime import datetime\n",
        "import psutil \n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "7rGU5scXqEbp"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
        "codebert = AutoModel.from_pretrained(\"microsoft/codebert-base\")\n",
        "MAX_TOKEN_DIM = 384 #controls padding and input to classifier\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(torch.cuda.is_available())\n",
        "print(device)\n",
        "if torch.cuda.is_available():\n",
        "  torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
        "  print(\"using cuda\")\n",
        "  \n",
        "torch.cuda.device(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-Ip-3YLpFJn",
        "outputId": "b9da18c1-f6a5-4cfd-a820-66e33d0caeab"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "cuda\n",
            "using cuda\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.cuda.device at 0x7f30972aeb90>"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data():\n",
        "  f = open(\"/content/drive/MyDrive/CloneData/data.jsonl\") #read sniipets and indices\n",
        "  entries = f.readlines()\n",
        "  objects = [json.loads(x) for x in entries] #load all functions\n",
        "  idx_to_function = dict()\n",
        " \n",
        "  for snippet in objects:#map to associate index to func\n",
        "    \n",
        "    idx_to_function[snippet[\"idx\"]] = snippet[\"func\"]\n",
        "\n",
        "  return idx_to_function"
      ],
      "metadata": {
        "id": "xhrTHlM6pOfa"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pairify_file(lines : list, idx_to_function : dict) -> tuple:\n",
        "  examples = []\n",
        "  \n",
        "  for line in lines:\n",
        "    line_entries = line.replace(\"\\t\", \" \").split(\" \") #given line x y label, divide to find if x is y according to label\n",
        "    #print(line)\n",
        "    x = line_entries[0]\n",
        "    y = line_entries[1]\n",
        "    label = line_entries[2]\n",
        "    \n",
        "    examples.append((idx_to_function[x], idx_to_function[y], float(label))) #convert label to float for pytorch\n",
        "  return examples\n"
      ],
      "metadata": {
        "id": "UiomZTWIp0rQ"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_and_label_data(idx_to_function : dict): #convert pairs to useful training examples\n",
        "  return tuple(map(  lambda x : pairify_file(open(x).readlines(), idx_to_function)  , [\"/content/drive/MyDrive/CloneData/train.txt\",\"/content/drive/MyDrive/CloneData/test.txt\", \"/content/drive/MyDrive/CloneData/valid.txt\"]))\n"
      ],
      "metadata": {
        "id": "49GUPqpspx2P"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "YQtpDvNstzDH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def embed(x : str) -> tuple:\n",
        "  with torch.no_grad():\n",
        "    code_tokens=tokenizer.tokenize(x)\n",
        "\n",
        "    if len(code_tokens) >= 510: #confirm tokes arent too big for model\n",
        "      return None\n",
        "    tokens=[tokenizer.cls_token]+code_tokens+[tokenizer.sep_token]\n",
        "\n",
        "    tokens_ids=tokenizer.convert_tokens_to_ids(tokens)\n",
        "    context_embeddings=codebert(torch.tensor(tokens_ids)[None,:])[0]\n",
        "    \n",
        "    flattened = torch.flatten(context_embeddings)\n",
        "    \n",
        "    \n",
        "    \n",
        "    return flattened #torch.clamp(flattened, min = -2, max = 2) #return flattened embedding vector"
      ],
      "metadata": {
        "id": "QLJLCUu4w0PY"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def embed_data(data : list) -> list: #takes prog1, prog2, label and replaces prog with their embedding for every item in the list and filters out too long items\n",
        "  embedded_data = []\n",
        "  i = 0\n",
        "  for x,y, label in data:\n",
        "    print(\"using {} MB for {} of {}, embedded {}\".format(psutil.Process().memory_info().rss / (1024 * 1024),i, len(data), len(embedded_data)))\n",
        "    emb_x = embed(x)\n",
        "    emb_y = embed(y)\n",
        "   \n",
        "    if emb_x != None and emb_y != None: #check code isnt too long\n",
        "      x_embed = emb_x #Standardize embeddings lengths since they depend on #of tokens\n",
        "      y_embed = emb_y\n",
        "     \n",
        "      padding_length_x  = (MAX_TOKEN_DIM * 768 - x_embed.size()[0])\n",
        "      padding_length_y  = (MAX_TOKEN_DIM * 768 - y_embed.size()[0])\n",
        "      \n",
        "      x_padded = torch.nn.functional.pad(x_embed, (int(padding_length_x/2), int(padding_length_x/2)))\n",
        "      y_padded = torch.nn.functional.pad(y_embed, (int(padding_length_y/2), int(padding_length_y/2)))\n",
        "      embedded_data.append((x_padded,y_padded, label))\n",
        "    i += 1\n",
        "  return embedded_data "
      ],
      "metadata": {
        "id": "ggTEK92rBaLQ"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CloneDataset(Dataset): #dataset \n",
        "\n",
        "  def __init__(self,x : list ,y : list,labels : list):\n",
        "    assert len(x) == len(y) and len(y) == len(labels) #make sure all the same size\n",
        "    #standard boilerplate\n",
        "    self.x = (x)\n",
        "    self.y = (y)\n",
        "    self.labels = torch.tensor(labels)\n",
        "    self.length = len(x)\n",
        "    \n",
        "  def __getitem__(self, idx):\n",
        "    return self.x[idx], self.y[idx], self.labels[idx]\n",
        "  \n",
        "  def __len__(self):\n",
        "    return self.length"
      ],
      "metadata": {
        "id": "00CK6wwm9MjH"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx_to_function = load_data()\n",
        "train_data, test_data,validation_data = split_and_label_data(idx_to_function)\n",
        "train_data = embed_data(train_data[:100])\n",
        "#test_data = embed_data(test_data)\n",
        "#validation_data = embed_data(validation_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hafzrTWspZ1P",
        "outputId": "154f4219-b8bf-440a-ccec-e4e0ec84539c"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1023 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using 10360.1328125 MB for 0 of 100, embedded 0\n",
            "using 10360.1328125 MB for 1 of 100, embedded 1\n",
            "using 10272.3828125 MB for 2 of 100, embedded 1\n",
            "using 10272.3828125 MB for 3 of 100, embedded 2\n",
            "using 10272.3828125 MB for 4 of 100, embedded 3\n",
            "using 10272.3828125 MB for 5 of 100, embedded 4\n",
            "using 10272.3828125 MB for 6 of 100, embedded 4\n",
            "using 10272.3828125 MB for 7 of 100, embedded 4\n",
            "using 10272.1328125 MB for 8 of 100, embedded 5\n",
            "using 10272.1328125 MB for 9 of 100, embedded 5\n",
            "using 10272.1328125 MB for 10 of 100, embedded 5\n",
            "using 10272.1328125 MB for 11 of 100, embedded 5\n",
            "using 10272.1328125 MB for 12 of 100, embedded 5\n",
            "using 10272.1328125 MB for 13 of 100, embedded 5\n",
            "using 10272.1328125 MB for 14 of 100, embedded 5\n",
            "using 10272.1328125 MB for 15 of 100, embedded 5\n",
            "using 10272.1328125 MB for 16 of 100, embedded 5\n",
            "using 10272.1328125 MB for 17 of 100, embedded 5\n",
            "using 10272.1328125 MB for 18 of 100, embedded 5\n",
            "using 10272.1328125 MB for 19 of 100, embedded 6\n",
            "using 10272.1328125 MB for 20 of 100, embedded 6\n",
            "using 10272.1328125 MB for 21 of 100, embedded 6\n",
            "using 10272.1328125 MB for 22 of 100, embedded 6\n",
            "using 10272.1328125 MB for 23 of 100, embedded 6\n",
            "using 10272.1328125 MB for 24 of 100, embedded 6\n",
            "using 10272.1328125 MB for 25 of 100, embedded 6\n",
            "using 10272.1328125 MB for 26 of 100, embedded 6\n",
            "using 10272.1328125 MB for 27 of 100, embedded 6\n",
            "using 10272.1328125 MB for 28 of 100, embedded 6\n",
            "using 10272.1328125 MB for 29 of 100, embedded 6\n",
            "using 10272.1328125 MB for 30 of 100, embedded 6\n",
            "using 10272.1328125 MB for 31 of 100, embedded 6\n",
            "using 10272.1328125 MB for 32 of 100, embedded 6\n",
            "using 10272.1328125 MB for 33 of 100, embedded 6\n",
            "using 10272.1328125 MB for 34 of 100, embedded 7\n",
            "using 10272.1328125 MB for 35 of 100, embedded 7\n",
            "using 10272.1328125 MB for 36 of 100, embedded 8\n",
            "using 10272.1328125 MB for 37 of 100, embedded 8\n",
            "using 10272.1328125 MB for 38 of 100, embedded 8\n",
            "using 10272.1328125 MB for 39 of 100, embedded 8\n",
            "using 10272.1328125 MB for 40 of 100, embedded 8\n",
            "using 10272.1328125 MB for 41 of 100, embedded 9\n",
            "using 10272.1328125 MB for 42 of 100, embedded 9\n",
            "using 10272.1328125 MB for 43 of 100, embedded 10\n",
            "using 10272.20703125 MB for 44 of 100, embedded 10\n",
            "using 10272.20703125 MB for 45 of 100, embedded 10\n",
            "using 10272.20703125 MB for 46 of 100, embedded 10\n",
            "using 10272.20703125 MB for 47 of 100, embedded 11\n",
            "using 10272.20703125 MB for 48 of 100, embedded 11\n",
            "using 10272.20703125 MB for 49 of 100, embedded 11\n",
            "using 10272.20703125 MB for 50 of 100, embedded 11\n",
            "using 10272.20703125 MB for 51 of 100, embedded 11\n",
            "using 10272.2109375 MB for 52 of 100, embedded 11\n",
            "using 10272.2109375 MB for 53 of 100, embedded 11\n",
            "using 10272.2109375 MB for 54 of 100, embedded 11\n",
            "using 10272.2109375 MB for 55 of 100, embedded 11\n",
            "using 10272.2109375 MB for 56 of 100, embedded 12\n",
            "using 10272.2109375 MB for 57 of 100, embedded 13\n",
            "using 10272.2109375 MB for 58 of 100, embedded 13\n",
            "using 10272.2109375 MB for 59 of 100, embedded 14\n",
            "using 10272.2109375 MB for 60 of 100, embedded 14\n",
            "using 10272.2109375 MB for 61 of 100, embedded 15\n",
            "using 10272.2109375 MB for 62 of 100, embedded 16\n",
            "using 10272.2109375 MB for 63 of 100, embedded 16\n",
            "using 10272.2109375 MB for 64 of 100, embedded 16\n",
            "using 10272.2109375 MB for 65 of 100, embedded 17\n",
            "using 10272.2109375 MB for 66 of 100, embedded 18\n",
            "using 10272.2109375 MB for 67 of 100, embedded 19\n",
            "using 10272.2109375 MB for 68 of 100, embedded 19\n",
            "using 10272.2109375 MB for 69 of 100, embedded 20\n",
            "using 10272.2109375 MB for 70 of 100, embedded 21\n",
            "using 10272.2109375 MB for 71 of 100, embedded 21\n",
            "using 10272.2109375 MB for 72 of 100, embedded 21\n",
            "using 10272.2109375 MB for 73 of 100, embedded 22\n",
            "using 10272.2109375 MB for 74 of 100, embedded 22\n",
            "using 10272.2109375 MB for 75 of 100, embedded 23\n",
            "using 10272.2109375 MB for 76 of 100, embedded 24\n",
            "using 10272.2109375 MB for 77 of 100, embedded 24\n",
            "using 10272.2109375 MB for 78 of 100, embedded 24\n",
            "using 10272.2109375 MB for 79 of 100, embedded 24\n",
            "using 10272.2109375 MB for 80 of 100, embedded 25\n",
            "using 10272.2109375 MB for 81 of 100, embedded 25\n",
            "using 10272.2109375 MB for 82 of 100, embedded 25\n",
            "using 10272.2109375 MB for 83 of 100, embedded 25\n",
            "using 10272.2109375 MB for 84 of 100, embedded 25\n",
            "using 10272.2109375 MB for 85 of 100, embedded 25\n",
            "using 10272.2109375 MB for 86 of 100, embedded 25\n",
            "using 10272.2109375 MB for 87 of 100, embedded 25\n",
            "using 10272.2109375 MB for 88 of 100, embedded 25\n",
            "using 10272.2109375 MB for 89 of 100, embedded 25\n",
            "using 10272.2109375 MB for 90 of 100, embedded 25\n",
            "using 10272.2109375 MB for 91 of 100, embedded 26\n",
            "using 10272.2109375 MB for 92 of 100, embedded 26\n",
            "using 10272.2109375 MB for 93 of 100, embedded 26\n",
            "using 10272.2109375 MB for 94 of 100, embedded 26\n",
            "using 10272.2109375 MB for 95 of 100, embedded 26\n",
            "using 10272.2109375 MB for 96 of 100, embedded 27\n",
            "using 10272.2109375 MB for 97 of 100, embedded 27\n",
            "using 10272.2109375 MB for 98 of 100, embedded 27\n",
            "using 10272.2109375 MB for 99 of 100, embedded 27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_dataset(data : list):\n",
        "  x_list = []\n",
        "  y_list = []\n",
        "  label_list = []\n",
        "  for x,y,l in data:#convert list of tuples to 3 separate lists\n",
        "    #x.to(device)\n",
        "    #y.to(device)\n",
        "\n",
        "    x_list.append(torch.flatten(x))\n",
        "    y_list.append(torch.flatten(y))\n",
        "    label_list.append(l)\n",
        "\n",
        "  return CloneDataset(x_list, y_list, label_list)"
      ],
      "metadata": {
        "id": "I9GsM8wgAXRT"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = build_dataset(train_data)\n",
        "trainLoader = DataLoader(train_data, batch_size= 3, shuffle = False)"
      ],
      "metadata": {
        "id": "YedE49quAN3_"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Classifier, self).__init__()\n",
        "        # Number of input features is 12.\n",
        "        #self.layer_1 = nn.Linear(12, 64) \n",
        "        #self.layer_2 = nn.Linear(64, 64)\n",
        "        #self.layer_out = nn.Linear(64, 1) \n",
        "        #\n",
        "        #self.relu = nn.ReLU()\n",
        "        #self.dropout = nn.Dropout(p=0.1)\n",
        "        #self.batchnorm1 = nn.BatchNorm1d(64)\n",
        "        #self.batchnorm2 = nn.BatchNorm1d(64)\n",
        "        \n",
        "        #A note on architecture for those interested, we eat CodeBERT embeddings of size X  * 768 which have been flattened\n",
        "        # Now those vectors are each fed into FF layer(s)\n",
        "        #Then they're concatnated and fed thru more FF layer(s)\n",
        "        # Then their dimensionality is shrunk down to 1, which is sigmoided\n",
        "        layer2_size = 512\n",
        "        layer3_size = 256\n",
        "        layer4_size = 32\n",
        "        self.xlayer_1 = nn.Linear(MAX_TOKEN_DIM * 768, layer2_size)\n",
        "        self.ylayer_1 = nn.Linear(MAX_TOKEN_DIM * 768, layer2_size)\n",
        "\n",
        "        self.ff1 = nn.Linear(2 * layer2_size, 1 )\n",
        "        #self.ff2 = nn.Linear(layer3_size, layer4_size)\n",
        "        #self.ff3 = nn.Linear(layer4_size, 1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "        nn.init.xavier_normal_(self.xlayer_1.weight)\n",
        "        nn.init.xavier_normal_(self.ylayer_1.weight)\n",
        "        nn.init.xavier_normal_(self.ff1.weight)\n",
        "        #nn.init.xavier_normal_(self.ff2.weight)\n",
        "        #nn.init.xavier_normal_(self.ff3.weight)\n",
        "\n",
        "        #self.to(device)\n",
        "\n",
        "\n",
        "    def forward(self, x,y):\n",
        "       #x = self.relu(self.layer_1(inputs))\n",
        "       #x = self.batchnorm1(x)\n",
        "       #x = self.relu(self.layer_2(x))\n",
        "       #x = self.batchnorm2(x)\n",
        "       #x = self.dropout(x)\n",
        "       #x = self.layer_out(x)\n",
        "       #\n",
        "       #return x\n",
        "       xtemp = self.xlayer_1(x)\n",
        "       xtemp = self.relu(xtemp)\n",
        "\n",
        "       ytemp = self.ylayer_1(y)\n",
        "       ytemp = self.relu(ytemp)\n",
        "\n",
        "       \n",
        "       combined = torch.cat((xtemp, ytemp),1)\n",
        "      \n",
        "       out = self.ff1(combined)\n",
        "       #out = self.relu(out)\n",
        "       #out = self.ff2(out)\n",
        "       #out = self.relu(out)\n",
        "       #out = self.ff3(out)\n",
        "       \n",
        "       #out = self.sigmoid(out)\n",
        "       return out\n"
      ],
      "metadata": {
        "id": "eZZu9vOmt8tm"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "  epochs  = 3 #standard boilerplate\n",
        "  model = Classifier()\n",
        "  print(model.ff1.weight.device)\n",
        "  #criterion = nn.BCELoss()\n",
        "  criterion = nn.BCEWithLogitsLoss()\n",
        "  optimizer = optim.Adam(model.parameters())\n",
        "  \n",
        "\n",
        "  loss_history = []\n",
        "  f1_history = []\n",
        "  for epoch in range(epochs): #standard training procedure\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    tp_count = 0 #setup for f1 score\n",
        "    fp_count = 0\n",
        "    fn_count = 0\n",
        "    f1 = 0\n",
        "    \n",
        "    j = 0\n",
        "    for x,y, label in trainLoader:\n",
        "      \n",
        "      start = datetime.now()\n",
        "      optimizer.zero_grad()\n",
        "      print(x.dtype)\n",
        "      print(\"max x {}\".format(torch.max(x)))\n",
        "     \n",
        "      pred = model(x,y)\n",
        "      pred.to(\"cpu\")\n",
        "      label.to(\"cpu\")\n",
        "      print(pred)\n",
        "\n",
        "\n",
        "      #print(label.shape)\n",
        "      #print(pred.view(10).shape)\n",
        "      loss = criterion(torch.flatten(pred.unsqueeze(1)),torch.flatten(label.unsqueeze(1)))\n",
        "      loss.backward()\n",
        "      #nn.utils.clip_grad_norm_(model.parameters(), max_norm = 2.0, norm_type = 2.0)\n",
        "      optimizer.step()\n",
        "      #print(\"pred is {}\".format(pred))\n",
        "      epoch_loss += loss.item()\n",
        "\n",
        "      #calculate scores\n",
        "      pred_rounded = torch.round(pred)\n",
        "      for i in range(label.shape[0]):\n",
        "        if pred_rounded[i] == 1 and label[i] == 1:\n",
        "          tp_count += 1\n",
        "        elif pred_rounded[i] == 1 and label[i] == 0:\n",
        "          fp_count += 1\n",
        "        elif pred_rounded[i] == 0 and label[i] == 1:\n",
        "          fn_count += 1\n",
        "      \n",
        "      end = datetime.now()\n",
        "      delta_t = end-start \n",
        "\n",
        "      \n",
        "      if (tp_count + .5 * (fp_count + fn_count)) != 0: #dont get 0 for denom of f1\n",
        "        f1 = tp_count/(tp_count + .5 * (fp_count + fn_count))\n",
        "      if j % 2 == 0:\n",
        "        print(\"time per iteration {} s\".format(delta_t.microseconds / 10**6))\n",
        "        print(\"at iteration{} of epoch {} total loss is {} , f1 is {}, tp is {}, current loss is {}\".format(j,epoch,epoch_loss, f1, tp_count, loss.item()))\n",
        "      j+=1\n",
        "      loss_history.append(loss.item())\n",
        "      f1_history.append(f1)\n",
        "\n",
        "  return (loss_history,f1_history)"
      ],
      "metadata": {
        "id": "mDmyDuz6wuN7"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_history, f1_history = train()"
      ],
      "metadata": {
        "id": "Gsr8-zrrzR7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(list(range(len(f1_history))), f1_history)\n",
        "plt.title(\"F1 score\")\n",
        "plt.xlabel(\"Iterations\")\n",
        "plt.ylabel(\"F1\")\n",
        "plt.show()\n",
        "plt.scatter(list(range(len(loss_history))), loss_history)\n",
        "plt.title(\"Loss\")\n",
        "plt.xlabel(\"Iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5hDwOnK2p_AY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "0d78414b-7d13-4098-8596-1a41a0806ec3"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}