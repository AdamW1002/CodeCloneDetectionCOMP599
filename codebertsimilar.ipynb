{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "codebertsimilar.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM4vuP9LL+8rFdi4ut7bGkG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdamW1002/CodeCloneDetectionCOMP599/blob/main/codebertsimilar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0VZBFbTlCR-",
        "outputId": "56b1de50-0bde-453f-ddbc-7ee867d93c8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 4.3 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 39.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 46.3 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,>=0.11.1\n",
            "  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 46.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.11.6 transformers-4.17.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip data.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tylcpscmoXQJ",
        "outputId": "5bac7b6c-463b-49a4-c4fb-bfe5ec38531c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  data.zip\n",
            "   creating: content/CodeT5/data/clone/\n",
            "  inflating: content/CodeT5/data/clone/train.txt  \n",
            "  inflating: content/CodeT5/data/clone/data.jsonl  \n",
            "  inflating: content/CodeT5/data/clone/test.txt  \n",
            "  inflating: content/CodeT5/data/clone/valid.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
        "model = AutoModel.from_pretrained(\"microsoft/codebert-base\")\n",
        "MAX_TOKEN_DIM = 384 #controls padding and input to classifier"
      ],
      "metadata": {
        "id": "U-Ip-3YLpFJn"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data():\n",
        "  f = open(\"data.jsonl\") #read sniipets and indices\n",
        "  entries = f.readlines()\n",
        "  objects = [json.loads(x) for x in entries] #load all functions\n",
        "  idx_to_function = dict()\n",
        " \n",
        "  for snippet in objects:#map to associate index to func\n",
        "    \n",
        "    idx_to_function[snippet[\"idx\"]] = snippet[\"func\"]\n",
        "\n",
        "  return idx_to_function"
      ],
      "metadata": {
        "id": "xhrTHlM6pOfa"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pairify_file(lines : list, idx_to_function : dict) -> tuple:\n",
        "  examples = []\n",
        "  \n",
        "  for line in lines:\n",
        "    line_entries = line.replace(\"\\t\", \" \").split(\" \") #given line x y label, divide to find if x is y according to label\n",
        "    #print(line)\n",
        "    x = line_entries[0]\n",
        "    y = line_entries[1]\n",
        "    label = line_entries[2]\n",
        "    \n",
        "    examples.append((idx_to_function[x], idx_to_function[y], float(label))) #convert label to float for pytorch\n",
        "  return examples\n"
      ],
      "metadata": {
        "id": "UiomZTWIp0rQ"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_and_label_data(idx_to_function : dict): #convert pairs to useful training examples\n",
        "  return tuple(map(  lambda x : pairify_file(open(x).readlines(), idx_to_function)  , [\"train.txt\",\"test.txt\", \"valid.txt\"]))\n"
      ],
      "metadata": {
        "id": "49GUPqpspx2P"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx_to_function = load_data()\n",
        "train_data, test_data,validation_data = split_and_label_data(idx_to_function)"
      ],
      "metadata": {
        "id": "hafzrTWspZ1P"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "YQtpDvNstzDH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_data[0][0])\n",
        "print(test_data[0][1])\n",
        "print(test_data[0][2])"
      ],
      "metadata": {
        "id": "WzSahqZgtgr1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def embed(x : str) -> tuple:\n",
        "  code_tokens=tokenizer.tokenize(x)\n",
        "  tokens=[tokenizer.cls_token]+code_tokens[:510]+[tokenizer.sep_token]\n",
        "\n",
        "  tokens_ids=tokenizer.convert_tokens_to_ids(tokens)\n",
        "  context_embeddings=model(torch.tensor(tokens_ids)[None,:])[0]\n",
        "  return torch.flatten(context_embeddings) #return flattened embedding vector"
      ],
      "metadata": {
        "id": "QLJLCUu4w0PY"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Classifier, self).__init__()\n",
        "        # Number of input features is 12.\n",
        "        #self.layer_1 = nn.Linear(12, 64) \n",
        "        #self.layer_2 = nn.Linear(64, 64)\n",
        "        #self.layer_out = nn.Linear(64, 1) \n",
        "        #\n",
        "        #self.relu = nn.ReLU()\n",
        "        #self.dropout = nn.Dropout(p=0.1)\n",
        "        #self.batchnorm1 = nn.BatchNorm1d(64)\n",
        "        #self.batchnorm2 = nn.BatchNorm1d(64)\n",
        "        \n",
        "        #A note on architecture for those interested, we eat CodeBERT embeddings of size X  * 768 which have been flattened\n",
        "        # Now those vectors are each fed into FF layer(s)\n",
        "        #Then they're concatnated and fed thru more FF layer(s)\n",
        "        # Then their dimensionality is shrunk down to 1, which is sigmoided\n",
        "        layer2_size = 256\n",
        "        self.xlayer_1 = nn.Linear(MAX_TOKEN_DIM * 768, layer2_size)\n",
        "        self.ylayer_1 = nn.Linear(MAX_TOKEN_DIM * 768, layer2_size)\n",
        "\n",
        "        self.ff1 = nn.Linear(2 * layer2_size, 1 )\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x,y):\n",
        "       #x = self.relu(self.layer_1(inputs))\n",
        "       #x = self.batchnorm1(x)\n",
        "       #x = self.relu(self.layer_2(x))\n",
        "       #x = self.batchnorm2(x)\n",
        "       #x = self.dropout(x)\n",
        "       #x = self.layer_out(x)\n",
        "       #\n",
        "       #return x\n",
        "       xtemp = self.xlayer_1(x)\n",
        "       xtemp = self.relu(xtemp)\n",
        "\n",
        "       ytemp = self.ylayer_1(y)\n",
        "       ytemp = self.relu(ytemp)\n",
        "\n",
        "       combined = torch.cat((xtemp, ytemp),0)\n",
        "       out = self.ff1(combined)\n",
        "       out = self.sigmoid(out)\n",
        "       return out\n"
      ],
      "metadata": {
        "id": "eZZu9vOmt8tm"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "  epochs  = 3 #standard boilerplate\n",
        "  model = Classifier()\n",
        "  criterion = nn.BCELoss()\n",
        "  optimizer = optim.Adam(model.parameters())\n",
        "  \n",
        "  for epoch in range(epochs): #standard training procedure\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    tp_count = 0 #setup for f1 score\n",
        "    fp_count = 0\n",
        "    fn_count = 0\n",
        "    f1 = 0\n",
        "    \n",
        "    i = 0\n",
        "    for x,y, label in train_data:\n",
        "      optimizer.zero_grad()\n",
        "      x_embed = embed(x) #get and pad embeddings\n",
        "      y_embed = embed(y)\n",
        "     \n",
        "      padding_length_x  = (MAX_TOKEN_DIM * 768 - x_embed.size()[0])\n",
        "      padding_length_y  = (MAX_TOKEN_DIM * 768 - y_embed.size()[0])\n",
        "      \n",
        "      x_padded = torch.nn.functional.pad(x_embed, (int(padding_length_x/2), int(padding_length_x/2)))\n",
        "      y_padded = torch.nn.functional.pad(y_embed, (int(padding_length_y/2), int(padding_length_y/2)))\n",
        "     \n",
        "       \n",
        "      pred = model(x_padded,y_padded)\n",
        "\n",
        "      loss = criterion(pred,torch.tensor([label]))\n",
        "      loss.backward()\n",
        "\n",
        "      epoch_loss += loss.item()\n",
        "\n",
        "      #calculate scores\n",
        "      pred_rounded = torch.round(pred)\n",
        "      if pred_rounded == 1 and label == 1:\n",
        "        tp_count += 1\n",
        "      elif pred_rounded == 1 and label == 0:\n",
        "        fp_count += 1\n",
        "      elif pred_rounded == 0 and label == 1:\n",
        "        fn_count += 1\n",
        "      \n",
        "      if (tp_count + .5 * (fp_count + fn_count)) != 0:\n",
        "        f1 = tp_count/(tp_count + .5 * (fp_count + fn_count))\n",
        "      if i %1 == 0:\n",
        "        print(\"loss is {} and f1 is {}\".format(epoch_loss, f1))\n",
        "      i+=1\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mDmyDuz6wuN7"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gsr8-zrrzR7_",
        "outputId": "94238c0c-45ad-400d-857b-5d889e00c293"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss is 57.41894340515137 and f1 is 0.5609756097560976\n",
            "torch.Size([393216])\n",
            "loss is 58.153509855270386 and f1 is 0.5542168674698795\n",
            "torch.Size([176640])\n"
          ]
        }
      ]
    }
  ]
}