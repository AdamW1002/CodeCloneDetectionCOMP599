{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "codebertsimilar.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1k0TyXLju0lXFekgkN7jI0yKHpLkiv5C7",
      "authorship_tag": "ABX9TyNtLIOtL3h71E0bIas3zn+D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdamW1002/CodeCloneDetectionCOMP599/blob/main/codebertsimilar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load required things and setup environment"
      ],
      "metadata": {
        "id": "qbT3SApH0bn7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0VZBFbTlCR-",
        "outputId": "b64fd9da-c28e-4c09-bfeb-6ff86932f61c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 15.3 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 65.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 6.4 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 69.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers!=0.11.3,>=0.11.1\n",
            "  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 64.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.11.6 transformers-4.17.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from datetime import datetime\n",
        "import psutil \n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "7rGU5scXqEbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "MAX_TOKEN_DIM = 384 #controls padding and input to classifier\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(torch.cuda.is_available())\n",
        "print(device)\n",
        "if torch.cuda.is_available():\n",
        "  torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
        "  print(\"using cuda\")\n",
        "  \n",
        "torch.cuda.device(device)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
        "codebert = AutoModel.from_pretrained(\"microsoft/codebert-base\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-Ip-3YLpFJn",
        "outputId": "6608aff4-8737-4397-92ae-e102e1fc3411"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "cuda\n",
            "using cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data():\n",
        "  f = open(\"/content/drive/MyDrive/CloneData/data.jsonl\") #read sniipets and indices\n",
        "  entries = f.readlines()\n",
        "  objects = [json.loads(x) for x in entries] #load all functions\n",
        "  idx_to_function = dict()\n",
        " \n",
        "  for snippet in objects:#map to associate index to func\n",
        "    \n",
        "    idx_to_function[snippet[\"idx\"]] = snippet[\"func\"]\n",
        "\n",
        "  return idx_to_function"
      ],
      "metadata": {
        "id": "xhrTHlM6pOfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pairify_file(lines : list, idx_to_function : dict) -> tuple:\n",
        "  examples = []\n",
        "  \n",
        "  for line in lines:\n",
        "    line_entries = line.replace(\"\\t\", \" \").split(\" \") #given line x y label, divide to find if x is y according to label\n",
        "    #print(line)\n",
        "    x = line_entries[0]\n",
        "    y = line_entries[1]\n",
        "    label = line_entries[2]\n",
        "    \n",
        "    examples.append((idx_to_function[x], idx_to_function[y], float(label))) #convert label to float for pytorch\n",
        "  return examples\n"
      ],
      "metadata": {
        "id": "UiomZTWIp0rQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_and_label_data(idx_to_function : dict): #convert pairs to useful training examples\n",
        "  return tuple(map(  lambda x : pairify_file(open(x).readlines(), idx_to_function)  , [\"/content/drive/MyDrive/CloneData/train.txt\",\"/content/drive/MyDrive/CloneData/test.txt\", \"/content/drive/MyDrive/CloneData/valid.txt\"]))\n"
      ],
      "metadata": {
        "id": "49GUPqpspx2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-calculate embeddings"
      ],
      "metadata": {
        "id": "4EYrKogx0kQo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def embed(x : str) -> tuple:\n",
        "  with torch.no_grad():\n",
        "    code_tokens=tokenizer.tokenize(x)\n",
        "\n",
        "    if len(code_tokens) >= 510: #confirm tokes arent too big for model\n",
        "      return None\n",
        "    tokens=[tokenizer.cls_token]+code_tokens+[tokenizer.sep_token]\n",
        "\n",
        "    tokens_ids=tokenizer.convert_tokens_to_ids(tokens)\n",
        "    context_embeddings=codebert(torch.tensor(tokens_ids, device = device)[None,:])[0]\n",
        "    \n",
        "    flattened = torch.flatten(context_embeddings)\n",
        "    print()\n",
        "    \n",
        "    \n",
        "    return flattened #torch.clamp(flattened, min = -2, max = 2) #return flattened embedding vector"
      ],
      "metadata": {
        "id": "QLJLCUu4w0PY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def embed_data(data : list) -> list: #takes prog1, prog2, label and replaces prog with their embedding for every item in the list and filters out too long items\n",
        "  embedded_data = []\n",
        "  i = 0\n",
        "  for x,y, label in data:\n",
        "    print(\"using {} MB for {} of {}, embedded {}\".format(psutil.Process().memory_info().rss / (1024 * 1024),i, len(data), len(embedded_data)))\n",
        "    emb_x = embed(x)\n",
        "    emb_y = embed(y)\n",
        "   \n",
        "    if emb_x != None and emb_y != None: #check code isnt too long\n",
        "      x_embed = emb_x #Standardize embeddings lengths since they depend on #of tokens\n",
        "      y_embed = emb_y\n",
        "     \n",
        "      padding_length_x  = (MAX_TOKEN_DIM * 768 - x_embed.size()[0])\n",
        "      padding_length_y  = (MAX_TOKEN_DIM * 768 - y_embed.size()[0])\n",
        "      \n",
        "      x_padded = torch.nn.functional.pad(x_embed, (int(padding_length_x/2), int(padding_length_x/2)))\n",
        "      y_padded = torch.nn.functional.pad(y_embed, (int(padding_length_y/2), int(padding_length_y/2)))\n",
        "      embedded_data.append((x_padded,y_padded, label))\n",
        "    i += 1\n",
        "  return embedded_data "
      ],
      "metadata": {
        "id": "ggTEK92rBaLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CloneDataset(Dataset): #dataset \n",
        "\n",
        "  def __init__(self,x : list ,y : list,labels : list):\n",
        "    assert len(x) == len(y) and len(y) == len(labels) #make sure all the same size\n",
        "    #standard boilerplate\n",
        "    self.x = (x)\n",
        "    self.y = (y)\n",
        "    self.labels = torch.tensor(labels)\n",
        "    self.length = len(x)\n",
        "    \n",
        "  def __getitem__(self, idx):\n",
        "    return self.x[idx], self.y[idx], self.labels[idx]\n",
        "  \n",
        "  def __len__(self):\n",
        "    return self.length"
      ],
      "metadata": {
        "id": "00CK6wwm9MjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#test_data = embed_data(test_data)\n",
        "#validation_data = embed_data(validation_data)"
      ],
      "metadata": {
        "id": "hafzrTWspZ1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_dataset(data : list):\n",
        "  x_list = []\n",
        "  y_list = []\n",
        "  label_list = []\n",
        "  for x,y,l in data:#convert list of tuples to 3 separate lists\n",
        "    #x.to(device)\n",
        "    #y.to(device)\n",
        "\n",
        "    x_list.append(torch.flatten(x))\n",
        "    y_list.append(torch.flatten(y))\n",
        "    label_list.append(l)\n",
        "\n",
        "  return CloneDataset(x_list, y_list, label_list)"
      ],
      "metadata": {
        "id": "I9GsM8wgAXRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Classifier, self).__init__()\n",
        "        # Number of input features is 12.\n",
        "        #self.layer_1 = nn.Linear(12, 64) \n",
        "        #self.layer_2 = nn.Linear(64, 64)\n",
        "        #self.layer_out = nn.Linear(64, 1) \n",
        "        #\n",
        "        #self.relu = nn.ReLU()\n",
        "        #self.dropout = nn.Dropout(p=0.1)\n",
        "        #self.batchnorm1 = nn.BatchNorm1d(64)\n",
        "        #self.batchnorm2 = nn.BatchNorm1d(64)\n",
        "        \n",
        "        #A note on architecture for those interested, we eat CodeBERT embeddings of size X  * 768 which have been flattened\n",
        "        # Now those vectors are each fed into FF layer(s)\n",
        "        #Then they're concatnated and fed thru more FF layer(s)\n",
        "        # Then their dimensionality is shrunk down to 1, which is sigmoided\n",
        "        layer2_size = 512\n",
        "        layer3_size = 256\n",
        "        layer4_size = 32\n",
        "        self.xlayer_1 = nn.Linear(MAX_TOKEN_DIM * 768, layer2_size)\n",
        "        self.ylayer_1 = nn.Linear(MAX_TOKEN_DIM * 768, layer2_size)\n",
        "\n",
        "        self.ff1 = nn.Linear(2 * layer2_size, 1 )\n",
        "        #self.ff2 = nn.Linear(layer3_size, 1)\n",
        "        #self.ff3 = nn.Linear(layer4_size, 1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "        nn.init.xavier_normal_(self.xlayer_1.weight)\n",
        "        nn.init.xavier_normal_(self.ylayer_1.weight)\n",
        "        nn.init.xavier_normal_(self.ff1.weight)\n",
        "        #nn.init.xavier_normal_(self.ff2.weight)\n",
        "        #nn.init.xavier_normal_(self.ff3.weight)\n",
        "\n",
        "        #self.to(device)\n",
        "\n",
        "\n",
        "    def forward(self, x,y):\n",
        "       #x = self.relu(self.layer_1(inputs))\n",
        "       #x = self.batchnorm1(x)\n",
        "       #x = self.relu(self.layer_2(x))\n",
        "       #x = self.batchnorm2(x)\n",
        "       #x = self.dropout(x)\n",
        "       #x = self.layer_out(x)\n",
        "       #\n",
        "       #return x\n",
        "       xtemp = self.xlayer_1(x)\n",
        "       xtemp = self.sigmoid(xtemp)\n",
        "\n",
        "       ytemp = self.ylayer_1(y)\n",
        "       ytemp = self.sigmoid(ytemp)\n",
        "\n",
        "       \n",
        "       combined = torch.cat((xtemp, ytemp),1)\n",
        "      \n",
        "       out = self.ff1(combined)\n",
        "       #out = self.sigmoid(out)\n",
        "       #out = self.ff2(out)\n",
        "       #out = self.relu(out)\n",
        "       #out = self.ff3(out)\n",
        "       \n",
        "       #out = self.sigmoid(out)\n",
        "       return out\n"
      ],
      "metadata": {
        "id": "eZZu9vOmt8tm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx_to_function = load_data()\n",
        "train_data, test_data,validation_data = split_and_label_data(idx_to_function)\n",
        "train_data = embed_data(train_data[:2000])\n",
        "train_data = build_dataset(train_data)\n",
        "trainLoader = DataLoader(train_data, batch_size= 100, shuffle = False)"
      ],
      "metadata": {
        "id": "p6LWC8lU0SGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train model"
      ],
      "metadata": {
        "id": "AXLGEVbK0qda"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "  epochs  = 10 #standard boilerplate\n",
        "  model = Classifier()\n",
        "  print(model.ff1.weight.device)\n",
        "  #criterion = nn.BCELoss()\n",
        "  criterion = nn.BCEWithLogitsLoss()\n",
        "  optimizer = optim.Adam(model.parameters())\n",
        "  \n",
        "\n",
        "  loss_history = []\n",
        "  f1_history = []\n",
        "  for epoch in range(epochs): #standard training procedure\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    tp_count = 0 #setup for f1 score\n",
        "    fp_count = 0\n",
        "    fn_count = 0\n",
        "    f1 = 0\n",
        "    \n",
        "    j = 0\n",
        "    for x,y, label in trainLoader:\n",
        "      \n",
        "      start = datetime.now()\n",
        "      optimizer.zero_grad()\n",
        "      print(x.dtype)\n",
        "      print(\"max x {}\".format(torch.max(x)))\n",
        "     \n",
        "      pred = model(x,y)\n",
        "      pred.to(\"cpu\")\n",
        "      label.to(\"cpu\")\n",
        "      #print(pred)\n",
        "\n",
        "\n",
        "      #print(label.shape)\n",
        "      #print(pred.view(10).shape)\n",
        "      loss = criterion(torch.flatten(pred.unsqueeze(1)),torch.flatten(label.unsqueeze(1)))\n",
        "      loss.backward()\n",
        "      nn.utils.clip_grad_norm_(model.parameters(), max_norm = 2.0, norm_type = 2.0)\n",
        "      optimizer.step()\n",
        "      #print(\"pred is {}\".format(pred))\n",
        "      epoch_loss += loss.item()\n",
        "\n",
        "      #calculate scores\n",
        "      pred_rounded = torch.round(pred)\n",
        "      for i in range(label.shape[0]):\n",
        "        if pred_rounded[i] == 1 and label[i] == 1:\n",
        "          tp_count += 1\n",
        "        elif pred_rounded[i] == 1 and label[i] == 0:\n",
        "          fp_count += 1\n",
        "        elif pred_rounded[i] == 0 and label[i] == 1:\n",
        "          fn_count += 1\n",
        "      \n",
        "      end = datetime.now()\n",
        "      delta_t = end-start \n",
        "\n",
        "      \n",
        "      if (tp_count + .5 * (fp_count + fn_count)) != 0: #dont get 0 for denom of f1\n",
        "        f1 = tp_count/(tp_count + .5 * (fp_count + fn_count))\n",
        "      if j % 10 == 0:\n",
        "        print(\"time per iteration {} s\".format(delta_t.microseconds / 10**6))\n",
        "        print(\"at iteration{} of epoch {} total loss is {} , f1 is {}, tp is {}, current loss is {}\".format(j,epoch,epoch_loss, f1, tp_count, loss.item()))\n",
        "      j+=1\n",
        "      loss_history.append(loss.item())\n",
        "      f1_history.append(f1)\n",
        "\n",
        "  return (loss_history,f1_history)"
      ],
      "metadata": {
        "id": "mDmyDuz6wuN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_history, f1_history = train()"
      ],
      "metadata": {
        "id": "Gsr8-zrrzR7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analzye results"
      ],
      "metadata": {
        "id": "W-4-FxV90s_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(list(range(len(f1_history))), f1_history)\n",
        "plt.title(\"F1 score\")\n",
        "plt.xlabel(\"Iterations\")\n",
        "plt.ylabel(\"F1\")\n",
        "plt.show()\n",
        "plt.scatter(list(range(len(loss_history))), loss_history)\n",
        "plt.title(\"Loss\")\n",
        "plt.xlabel(\"Iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5hDwOnK2p_AY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "f17b2440-a11b-4f83-8f4b-d8654cd7d48a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}