{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "codebertsimilar.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1k0TyXLju0lXFekgkN7jI0yKHpLkiv5C7",
      "authorship_tag": "ABX9TyPZ1//uCLe6g05Gb+XUiZLQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdamW1002/CodeCloneDetectionCOMP599/blob/main/codebertsimilar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load required things and setup environment"
      ],
      "metadata": {
        "id": "qbT3SApH0bn7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cloud-tpu-client==0.10 torch==1.11.0 https://storage.googleapis.com/tpu-pytorch/wheels/colab/torch_xla-1.11-cp37-cp37m-linux_x86_64.whl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84m73cj0zYi4",
        "outputId": "9f7b800b-7a9c-4999-f1f7-9d50e38401c8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-xla==1.11\n",
            "  Using cached https://storage.googleapis.com/tpu-pytorch/wheels/colab/torch_xla-1.11-cp37-cp37m-linux_x86_64.whl (152.9 MB)\n",
            "Requirement already satisfied: cloud-tpu-client==0.10 in /usr/local/lib/python3.7/dist-packages (0.10)\n",
            "Requirement already satisfied: torch==1.11.0 in /usr/local/lib/python3.7/dist-packages (1.11.0)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from cloud-tpu-client==0.10) (4.1.3)\n",
            "Requirement already satisfied: google-api-python-client==1.8.0 in /usr/local/lib/python3.7/dist-packages (from cloud-tpu-client==0.10) (1.8.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.11.0) (4.1.1)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.35.0)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.31.5)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.16.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (0.20.4)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.0.1)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (0.1.0)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.20.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.56.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2022.1)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (62.1.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (21.3)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.27.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (4.8)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.7/dist-packages (from httplib2<1dev,>=0.9.2->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.0.8)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (0.4.8)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2021.10.8)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.26.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0VZBFbTlCR-",
        "outputId": "57e71d46-32fe-4bac-ec0c-d8d1ec26cd22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.26.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.16.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from datetime import datetime\n",
        "import psutil \n",
        "import matplotlib.pyplot as plt\n",
        "import pdb\n",
        "\n",
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm\n",
        "import torch_xla.debug.metrics as met"
      ],
      "metadata": {
        "id": "7rGU5scXqEbp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe1eb6c1-bdca-4669-d89f-dfacea14b504"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:TPU has started up successfully with version pytorch-1.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "MAX_TOKEN_DIM = 512 #controls padding and input to classifier\n",
        "device = torch.device('cpu')\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda')\n",
        "  torch.cuda.device(device)\n",
        "try:\n",
        "  print(xm.xla_device())\n",
        "  device = xm.xla_device()\n",
        "  print(\"USING TPU\")\n",
        "except:\n",
        "  print(\"NOT USING TPU\")\n",
        "  pass\n",
        "print(torch.cuda.is_available())\n",
        "print(device)\n",
        "if torch.cuda.is_available():\n",
        "  torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
        "  print(\"using cuda\")\n",
        "  \n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
        "codebert = AutoModel.from_pretrained(\"microsoft/codebert-base\")\n",
        "torch.set_printoptions(precision=7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-Ip-3YLpFJn",
        "outputId": "39741a6a-4258-43c1-a776-b1c65b8180df"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "xla:1\n",
            "USING TPU\n",
            "False\n",
            "xla:1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data():\n",
        "  f = open(\"/content/drive/MyDrive/CloneData/data.jsonl\") #read sniipets and indices\n",
        "  entries = f.readlines()\n",
        "  objects = [json.loads(x) for x in entries] #load all functions\n",
        "  idx_to_function = dict()\n",
        " \n",
        "  for snippet in objects:#map to associate index to func\n",
        "    \n",
        "    idx_to_function[snippet[\"idx\"]] = snippet[\"func\"]\n",
        "\n",
        "  return idx_to_function"
      ],
      "metadata": {
        "id": "xhrTHlM6pOfa"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pairify_file(lines : list, idx_to_function : dict) -> tuple:\n",
        "  examples = []\n",
        "  \n",
        "  for line in lines:\n",
        "    line_entries = line.replace(\"\\t\", \" \").split(\" \") #given line x y label, divide to find if x is y according to label\n",
        "    #print(line)\n",
        "    x = line_entries[0]\n",
        "    y = line_entries[1]\n",
        "    label = line_entries[2]\n",
        "    \n",
        "    examples.append((idx_to_function[x], idx_to_function[y], float(label))) #convert label to float for pytorch\n",
        "  return examples\n"
      ],
      "metadata": {
        "id": "UiomZTWIp0rQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_and_label_data(idx_to_function : dict): #convert pairs to useful training examples\n",
        "  return tuple(map(  lambda x : pairify_file(open(x).readlines(), idx_to_function)  , [\"/content/drive/MyDrive/CloneData/train.txt\",\"/content/drive/MyDrive/CloneData/test.txt\", \"/content/drive/MyDrive/CloneData/valid.txt\"]))\n"
      ],
      "metadata": {
        "id": "49GUPqpspx2P"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-calculate embeddings"
      ],
      "metadata": {
        "id": "4EYrKogx0kQo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def embed(x : str) -> torch.TensorType:\n",
        "  with torch.no_grad():\n",
        "    code_tokens=tokenizer.tokenize(x)\n",
        "\n",
        "    if len(code_tokens) >= 510: #confirm tokes arent too big for model\n",
        "      return None\n",
        "    tokens=[tokenizer.cls_token]+code_tokens+[tokenizer.sep_token]\n",
        "\n",
        "    tokens_ids=tokenizer.convert_tokens_to_ids(tokens)\n",
        "    context_embeddings=codebert(torch.tensor(tokens_ids, device = device)[None,:])[0]\n",
        "    \n",
        "    flattened = torch.flatten(context_embeddings)\n",
        "    \n",
        "    \n",
        "    \n",
        "    return flattened #torch.clamp(flattened, min = -2, max = 2) #return flattened embedding vector"
      ],
      "metadata": {
        "id": "QLJLCUu4w0PY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def embed_data(data : list) -> list: #takes prog1, prog2, label and replaces prog with their embedding for every item in the list and filters out too long items\n",
        "  embedded_data = []\n",
        "  i = 0\n",
        "  \n",
        "  for x,y, label in data:\n",
        "\n",
        "    if i % 10 == 0:  \n",
        "      #print(\"using {} MB for {} of {}, embedded {}\".format(psutil.Process().memory_info().rss / (1024 * 1024),i, len(data), len(embedded_data)))\n",
        "      pass\n",
        "    emb_x = embed(x[0])\n",
        "    emb_y = embed(y[0])\n",
        "    #pdb.set_trace()\n",
        "    if emb_x != None and emb_y != None: #check code isnt too long\n",
        "      x_embed = emb_x #Standardize embeddings lengths since they depend on #of tokens\n",
        "      y_embed = emb_y\n",
        "     \n",
        "      padding_length_x  = (MAX_TOKEN_DIM * 768 - x_embed.size()[0])\n",
        "      padding_length_y  = (MAX_TOKEN_DIM * 768 - y_embed.size()[0])\n",
        "      \n",
        "      x_padded = torch.nn.functional.pad(x_embed, (int(padding_length_x/2), int(padding_length_x/2)))\n",
        "      y_padded = torch.nn.functional.pad(y_embed, (int(padding_length_y/2), int(padding_length_y/2)))\n",
        "      embedded_data.append((x_padded,y_padded, label))\n",
        "    i += 1\n",
        "  #print(f\"unique entries {len(set([embedded_data[0][0],  embedded_data[1][0]]  ))}\")\n",
        "  return embedded_data "
      ],
      "metadata": {
        "id": "ggTEK92rBaLQ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CloneDataset(Dataset): #dataset \n",
        "\n",
        "  def __init__(self,x : list ,y : list,labels : list):\n",
        "    assert len(x) == len(y) and len(y) == len(labels) #make sure all the same size\n",
        "    #standard boilerplate\n",
        "    self.x = (x)\n",
        "    self.y = (y)\n",
        "    self.labels = labels\n",
        "    self.length = len(x)\n",
        "    \n",
        "  def __getitem__(self, idx):\n",
        "    return self.x[idx], self.y[idx], self.labels[idx]\n",
        "  \n",
        "  def __len__(self):\n",
        "    return self.length"
      ],
      "metadata": {
        "id": "00CK6wwm9MjH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#test_data = embed_data(test_data)\n",
        "#validation_data = embed_data(validation_data)"
      ],
      "metadata": {
        "id": "hafzrTWspZ1P"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(code : str) -> list:\n",
        "  with torch.no_grad():\n",
        "    code_tokens=tokenizer.tokenize(code)\n",
        "    \n",
        "\n",
        "    if len(code_tokens) >= 510: #confirm tokes arent too big for model\n",
        "      return None\n",
        "    code_tokens += [tokenizer.pad_token] *  (510 - len(code_tokens)) #pad out to 510 which becomes 512\n",
        "    tokens=[tokenizer.cls_token]+code_tokens+[tokenizer.sep_token]\n",
        "\n",
        "    tokens_ids=tokenizer.convert_tokens_to_ids(tokens)\n",
        "    return torch.tensor(tokens_ids, device = device)[None,:]"
      ],
      "metadata": {
        "id": "Bz8fusDHb6S7"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_dataset(data : list):\n",
        "  x_list = []\n",
        "  y_list = []\n",
        "  label_list = []\n",
        "  i = 0\n",
        "  for x,y,l in data:#convert list of tuples to 3 separate lists\n",
        "    #x.to(device)\n",
        "    #y.to(device)\n",
        "    if i % 250 == 0:\n",
        "        print(f\"on data point {i}\")\n",
        "    x_tokens = tokenize(x)\n",
        "    y_tokens = tokenize(y)\n",
        "    if  not x_tokens is None and not y_tokens is None: #confirmm both seqs work\n",
        "      x_list.append(x_tokens)\n",
        "      y_list.append(y_tokens)\n",
        "      label_list.append(l)\n",
        "    i+=1\n",
        "\n",
        "  return CloneDataset(x_list, y_list, label_list)"
      ],
      "metadata": {
        "id": "I9GsM8wgAXRT"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Classifier, self).__init__()\n",
        "       \n",
        "        \n",
        "        #A note on architecture for those interested, we eat CodeBERT embeddings of size X  * 768 which have been flattened\n",
        "        # Now those vectors are each fed into FF layer(s)\n",
        "        #Then they're concatnated and fed thru more FF layer(s)\n",
        "        # Then their dimensionality is shrunk down to 1, which is sigmoided\n",
        "        layer2_size = 512\n",
        "        layer3_size = 256\n",
        "        layer4_size = 32\n",
        "        #self.xlayer_1 = nn.Linear(MAX_TOKEN_DIM * 768, layer2_size)\n",
        "        #self.ylayer_1 = nn.Linear(MAX_TOKEN_DIM * 768, layer2_size)\n",
        "\n",
        "        self.ff1 = nn.Linear( 2 * MAX_TOKEN_DIM * 768, layer2_size )\n",
        "        self.ff2 = nn.Linear(layer2_size, 1)\n",
        "        #self.ff3 = nn.Linear(layer4_size, 1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "        self.batchNorm1 = nn.BatchNorm1d(layer2_size, affine = False)\n",
        "\n",
        "        #nn.init.xavier_normal_(self.xlayer_1.weight)\n",
        "        #nn.init.xavier_normal_(self.ylayer_1.weight)\n",
        "        nn.init.xavier_normal_(self.ff1.weight)\n",
        "        nn.init.xavier_normal_(self.ff2.weight)\n",
        "        #nn.init.xavier_normal_(self.ff3.weight)\n",
        "\n",
        "        #self.to(device)\n",
        "\n",
        "\n",
        "    def forward(self, x,y):\n",
        "      \n",
        "       combined = torch.cat((x, y),1)\n",
        "      \n",
        "       out = self.ff1(combined)\n",
        "       #print(f\"out is {out}\")\n",
        "       \n",
        "       out = self.sigmoid(out)\n",
        "       #xm.mark_step()\n",
        "       out = self.batchNorm1(out)\n",
        "       #xm.mark_step()\n",
        "       out = self.ff2(out)\n",
        "       #xm.mark_step()\n",
        "       #out = self.relu(out)\n",
        "       #out = self.ff3(out)\n",
        "       \n",
        "       #out = self.sigmoid(out)\n",
        "       return out\n"
      ],
      "metadata": {
        "id": "eZZu9vOmt8tm"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx_to_function = load_data()\n",
        "train_data, test_data,validation_data = split_and_label_data(idx_to_function)\n",
        "print(len(train_data))\n",
        "train_data = build_dataset(train_data[:3000])\n",
        "\n"
      ],
      "metadata": {
        "id": "p6LWC8lU0SGU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "128a6ccf-9adc-4c7e-a920-1f77f1d7bc04"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1023 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "901028\n",
            "on data point 0\n",
            "on data point 250\n",
            "on data point 500\n",
            "on data point 750\n",
            "on data point 1000\n",
            "on data point 1250\n",
            "on data point 1500\n",
            "on data point 1750\n",
            "on data point 2000\n",
            "on data point 2250\n",
            "on data point 2500\n",
            "on data point 2750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainLoader = DataLoader(train_data, batch_size= 128, shuffle = False, drop_last = True)# BATCH SIZES MUST BE MULTIPLES OF 128"
      ],
      "metadata": {
        "id": "iUqf_FPNTSKa"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class F1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(F1, self).__init__()\n",
        "       \n",
        "\n",
        "\n",
        "    def forward(self, label,pred):\n",
        "      with torch.no_grad():\n",
        "        x = torch.round(pred) - label\n",
        "        x  = torch.flatten(x)\n",
        "        tp = torch.where(x == 0, 1, 0)\n",
        "        tp_count = float(torch.numel(torch.nonzero(tp)))\n",
        "\n",
        "        fp = torch.where(x == 1, 1, 0)\n",
        "        fp_count = float(torch.numel(torch.nonzero(fp)))\n",
        "\n",
        "        fn = torch.where(x == -1, 1, 0)\n",
        "        fn_count = float(torch.numel(torch.nonzero(fn)))\n",
        "        denom = (tp_count + .5 * (fp_count + fn_count))\n",
        "        #print(tp_count, fp_count, fn_count)\n",
        "        #print(denom)\n",
        "        if denom == 0:\n",
        "          return 0\n",
        "        return float(tp_count) / float(denom)"
      ],
      "metadata": {
        "id": "Nf1LORXo3kIz"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train model"
      ],
      "metadata": {
        "id": "AXLGEVbK0qda"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "  torch.cuda.empty_cache() \n",
        "  epochs  = 2 #standard boilerplate\n",
        "  model = Classifier()\n",
        "  print(model.ff1.weight.device)\n",
        "  #criterion = nn.BCELoss()\n",
        "  criterion = nn.BCEWithLogitsLoss()\n",
        "  optimizer = optim.Adam(model.parameters())\n",
        "  scorer = F1()\n",
        "  scorer.to(device)\n",
        "\n",
        "  loss_history = []\n",
        "  f1_history = []\n",
        "  model.to(device)\n",
        "  codebert.to(device)\n",
        "  for epoch in range(epochs): #standard training procedure\n",
        "    torch.cuda.empty_cache() \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    tp_count = 0 #setup for f1 score\n",
        "    fp_count = 0\n",
        "    fn_count = 0\n",
        "    f1 = 0\n",
        "    \n",
        "    j = 0\n",
        "    for x,y,label in trainLoader:\n",
        "      torch.cuda.empty_cache() \n",
        "     \n",
        "      #print(f\"b0 {batch[0]}\")\n",
        "      #print(f\"b1 {batch[1]}\")\n",
        "      #print(f\"b2 {batch[2]}\")\n",
        "\n",
        "      with torch.no_grad():\n",
        "        x = torch.reshape(x, (x.shape[0], x.shape[2])) # make Batch size X 1 X 512 into Batch size X 512\n",
        "        y = torch.reshape(y, (y.shape[0], y.shape[2]))\n",
        "\n",
        "\n",
        "\n",
        "        \n",
        "       \n",
        "        #model.to(\"cpu\")\n",
        "        #codebert.to(device)\n",
        "        #print(f\"before embedding codebert is on {codebert.device}\")\n",
        "        embed_start = datetime.now()\n",
        "        embedded_x=codebert(x)[0]\n",
        "       \n",
        "        embedded_y=codebert(y)[0]\n",
        "       \n",
        "        embed_end = datetime.now()\n",
        "        #codebert.to(\"cpu\")\n",
        "        #model.to(device)\n",
        "        #print(embedded_x.shape)\n",
        "        #print(embedded_y.shape)\n",
        "        embedded_x.to('cpu')\n",
        "        embedded_y.to('cpu')\n",
        "        embedded_x = torch.flatten(embedded_x, start_dim = 1)\n",
        "        embedded_y = torch.flatten(embedded_y, start_dim = 1)\n",
        "        embedded_x.to(device)\n",
        "        embedded_y.to(device)\n",
        "        #print(embedded_x.shape)\n",
        "        #print(embedded_y.shape)\n",
        "       \n",
        "      \n",
        "      model_start = datetime.now()\n",
        "      optimizer.zero_grad()\n",
        "      #print(embedded_x.dtype)\n",
        "      #print(\"max x {}\".format(torch.max(embedded_x)))\n",
        "      #print(f\"before prediction model is on device {model.ff1.weight.device}\")\n",
        "      pred = model(embedded_x,embedded_y)\n",
        "      \n",
        "     \n",
        "      #print(f\"pred is {pred.shape} {pred}\")\n",
        "     \n",
        "\n",
        "\n",
        "      #print(label.shape)\n",
        "      #print(pred.view(10).shape)\n",
        "      loss_start = datetime.now()\n",
        "      loss = criterion(torch.flatten(pred.unsqueeze(1)),torch.flatten(label.unsqueeze(1)))\n",
        "      #loss = torch.nn.functional.binary_cross_entropy_with_logits(torch.flatten(pred.unsqueeze(1)),torch.flatten(label.unsqueeze(1)))\n",
        "      loss.backward()\n",
        "      #nn.utils.clip_grad_norm_(model.parameters(), max_norm = 2.0, norm_type = 2.0)\n",
        "      optimizer.step()\n",
        "      xm.mark_step()\n",
        "      \n",
        "      loss_end = datetime.now()\n",
        "      #print(\"pred is {}\".format(pred))\n",
        "      epoch_loss += loss.item()\n",
        "      end = datetime.now()\n",
        "      model_delta_t = end-model_start \n",
        "      embed_delta_t = embed_end-embed_start\n",
        "      loss_delta_t = loss_start-loss_end\n",
        "     \n",
        "     \n",
        "      with torch.no_grad():\n",
        "        f1_score = scorer(label,pred)\n",
        "        xm.mark_step()\n",
        "        score_start = datetime.now()\n",
        "        loss_history.append(loss.item())\n",
        "        f1_history.append(f1_score)\n",
        "        if j % 1 == 0:\n",
        "          print(torch.min(pred), torch.max(pred))\n",
        "          print(\"time per model iteration {} s\".format(model_delta_t.microseconds / 10**6))\n",
        "          print(\"time per embed iteration {} s\".format(embed_delta_t.microseconds / 10**6))\n",
        "          print(\"time per loss iteration {} s\".format(loss_delta_t.microseconds / 10**6))\n",
        "          \n",
        "          print(\"at iteration{} of epoch {} total loss is {} , f1 is {}, tp is {}, current loss is {}\".format(j,epoch,epoch_loss, f1_history[-1], tp_count, loss.item()))\n",
        "      j+=1\n",
        "      #print(met.metrics_report())\n",
        "      \n",
        "      \n",
        "        #\n",
        "        #calculate scores\n",
        "        #pred_rounded = torch.round(pred)\n",
        "        ##pred._rounded.to('cpu')\n",
        "        #print(label.shape)\n",
        "        #label.to('cpu')\n",
        "        #pred_rounded.to('cpu')\n",
        "        #for i in range(label.shape[0]):\n",
        "        #  #print(f\"i is {i}\")\n",
        "        #  if pred_rounded[i] == 1 and label[i] == 1:\n",
        "        #    tp_count += 1\n",
        "        #  elif pred_rounded[i] == 1 and label[i] == 0:\n",
        "        #    fp_count += 1\n",
        "        #  elif pred_rounded[i] == 0 and label[i] == 1:\n",
        "        #    fn_count += 1\n",
        "\n",
        "        #\n",
        "        #if (tp_count + .5 * (fp_count + fn_count)) != 0: #dont get 0 for denom of f1\n",
        "        #  f1 = tp_count/(tp_count + .5 * (fp_count + fn_count))\n",
        "        #\n",
        "        ##loss = loss.item.to('cpu')\n",
        "        #loss_history.append(loss.item())\n",
        "        #f1_history.append(f1)\n",
        "        #score_end = datetime.now()\n",
        "        #print(f\"{(score_end-score_start) / 10**6} s for scoring\")\n",
        "  return (loss_history,f1_history)"
      ],
      "metadata": {
        "id": "mDmyDuz6wuN7"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_history, f1_history = train()"
      ],
      "metadata": {
        "id": "Gsr8-zrrzR7_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7f5acb9b-afca-4ef7-ff25-d4659a059df5"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-61e7cf8c12c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-31-c57d00fbddee>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m       \u001b[0;31m#print(pred.view(10).shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m       \u001b[0mloss_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m       \u001b[0;31m#loss = torch.nn.functional.binary_cross_entropy_with_logits(torch.flatten(pred.unsqueeze(1)),torch.flatten(label.unsqueeze(1)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3063\u001b[0m         \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3064\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3065\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3067\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: torch_xla/csrc/aten_xla_bridge.cpp:69 : Check failed: xtensor \n*** Begin stack trace ***\n\ttensorflow::CurrentStackTrace()\n\ttorch_xla::bridge::GetXlaTensor(at::Tensor const&)\n\ttorch_xla::XLANativeFunctions::binary_cross_entropy(at::Tensor const&, at::Tensor const&, c10::optional<at::Tensor> const&, long)\n\t\n\tat::_ops::binary_cross_entropy::redispatch(c10::DispatchKeySet, at::Tensor const&, at::Tensor const&, c10::optional<at::Tensor> const&, long)\n\t\n\t\n\tat::_ops::binary_cross_entropy::call(at::Tensor const&, at::Tensor const&, c10::optional<at::Tensor> const&, long)\n\t\n\t_PyMethodDef_RawFastCallKeywords\n\t_PyCFunction_FastCallKeywords\n\t_PyEval_EvalFrameDefault\n\t_PyEval_EvalCodeWithName\n\t_PyFunction_FastCallKeywords\n\t_PyEval_EvalFrameDefault\n\t_PyObject_Call_Prepend\n\tPyObject_Call\n\t_PyEval_EvalFrameDefault\n\t_PyEval_EvalCodeWithName\n\t_PyObject_Call_Prepend\n\t\n\t_PyObject_FastCallKeywords\n\t_PyEval_EvalFrameDefault\n\t_PyFunction_FastCallKeywords\n\t_PyEval_EvalFrameDefault\n\t_PyEval_EvalCodeWithName\n\tPyEval_EvalCode\n\t\n\t_PyMethodDef_RawFastCallKeywords\n\t_PyCFunction_FastCallKeywords\n\t_PyEval_EvalFrameDefault\n\t_PyEval_EvalCodeWithName\n\t_PyFunction_FastCallKeywords\n\t_PyEval_EvalFrameDefault\n\t_PyEval_EvalCodeWithName\n\t_PyFunction_FastCallKeywords\n\t_PyEval_EvalFrameDefault\n\t_PyEval_EvalCodeWithName\n\t_PyObject_Call_Prepend\n\tPyObject_Call\n\t_PyEval_EvalFrameDefault\n\t_PyEval_EvalCodeWithName\n\t_PyFunction_FastCallKeywords\n\t_PyEval_EvalFrameDefault\n\t_PyEval_EvalCodeWithName\n\t_PyFunction_FastCallKeywords\n\t_PyEval_EvalFrameDefault\n\t_PyFunction_FastCallKeywords\n\t_PyEval_EvalFrameDefault\n\t_PyFunction_FastCallKeywords\n\t_PyEval_EvalFrameDefault\n\t_PyEval_EvalCodeWithName\n\t_PyFunction_FastCallDict\n\t_PyEval_EvalFrameDefault\n\t_PyEval_EvalCodeWithName\n\t_PyFunction_FastCallDict\n\t_PyEval_EvalFrameDefault\n\t_PyEval_EvalCodeWithName\n\t_PyFunction_FastCallKeywords\n\t_PyEval_EvalFrameDefault\n\t_PyFunction_FastCallKeywords\n\t_PyEval_EvalFrameDefault\n\t_PyObject_Call_Prepend\n\tPyObject_Call\n\t_PyEval_EvalFrameDefault\n\t_PyEval_EvalCodeWithName\n\t_PyFunction_FastCallKeywords\n\t_PyEval_EvalFrameDefault\n\t_PyObject_Call_Prepend\n\t_PyObject_FastCallKeywords\n\t\n\t_PyMethodDef_RawFastCallDict\n\tPyCFunction_Call\n\t_PyEval_EvalFrameDefault\n\t_PyFunction_FastCallKeywords\n\t_PyEval_EvalFrameDefault\n\t_PyFunction_FastCallKeywords\n\t_PyEval_EvalFrameDefault\n\t_PyFunction_FastCallKeywords\n\t_PyEval_EvalFrameDefault\n\t_PyFunction_FastCallKeywords\n\t_PyEval_EvalFrameDefault\n\t_PyFunction_FastCallKeywords\n\t_PyEval_EvalFrameDefault\n\t_PyEval_EvalCodeWithName\n\t_PyFunction_FastCallKeywords\n\t_PyEval_EvalFrameDefault\n\t_PyEval_EvalCodeWithName\n\tPyEval_EvalCode\n\t\n\t_PyMethodDef_RawFastCallKeywords\n\t_PyCFunction_FastCallKeywords\n\t_PyEval_EvalFrameDefault\n\t_PyEval_EvalCodeWithName\n\t_PyFunction_FastCallKeywords\n\t_PyEval_EvalFrameDefault\n\t_PyEval_EvalCodeWithName\n\t_PyFunction_FastCallDict\n\t\n\t\n\t_Py_UnixMain\n\t__libc_start_main\n\t_start\n*** End stack trace ***\nInput tensor is not an XLA tensor: torch.DoubleTensor"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analzye results"
      ],
      "metadata": {
        "id": "W-4-FxV90s_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(list(range(len(f1_history))), f1_history)\n",
        "plt.title(\"F1 score\")\n",
        "plt.xlabel(\"Iterations\")\n",
        "plt.ylabel(\"F1\")\n",
        "plt.show()\n",
        "plt.scatter(list(range(len(loss_history))), loss_history)\n",
        "plt.title(\"Loss\")\n",
        "plt.xlabel(\"Iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5hDwOnK2p_AY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "f51613e0-308e-460f-81c6-a4a8a6ce115b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAbJUlEQVR4nO3df5RfdX3n8efLIUBqhWgz7YEESLpNo7FUaEeqa6tuqU1kWaC4q7D4a+uRui20WpqWbGlr2Xa1J27r9izaxRapFuFwKGJOq41W8cfp4jaDCQmBjUb8QSZYx6URWlMJ8b1/fO/gN5NJMjfJd77znXk+zvmeufdzf/C+8Jl5ce/nfu9NVSFJ0nQ9rd8FSJIGi8EhSWrF4JAktWJwSJJaMTgkSa0YHJKkVgwOSVIrBod0HCX5cpKf6XcdUi8ZHJKkVgwOqceSnJTknUl2N593JjmpWbY4yV8l2ZPk0SSfSfK0ZtlvJBlL8niSHUnO7++RSB0n9LsAaR74TeAFwDlAAR8CrgN+C7gG2AUMN+u+AKgkK4GrgOdX1e4ky4ChmS1bmppnHFLvXQFcX1Vfr6px4HeB1zTL9gGnAWdV1b6q+kx1HiC3HzgJWJVkQVV9uaq+2JfqpUkMDqn3Tge+0jX/laYNYD2wE/hokoeSXAtQVTuBNwNvBb6e5LYkpyPNAgaH1Hu7gbO65s9s2qiqx6vqmqr6QeAi4FcnxjKq6gNV9ZPNtgX8wcyWLU3N4JCOvwVJTp74ALcC1yUZTrIY+G3gLwCSXJjkh5IE+CadS1TfSbIyyU83g+j/AuwFvtOfw5EOZHBIx9+H6fyhn/icDIwCW4FtwOeA32vWXQH8LfBPwD3Au6rqbjrjG28HvgF8Dfh+YN3MHYJ0aPFFTpKkNjzjkCS1YnBIkloxOCRJrRgckqRW5sUjRxYvXlzLli3rdxmSNFDuvffeb1TV8OT2eREcy5YtY3R0tN9lSNJASfKVqdq9VCVJasXgkCS1YnBIkloxOCRJrRgckqRW5sVdVbPNXZvHWL9xB7v37OX0RQtZu3oll5y7pN9laZ6yP6otg2OG3bV5jHV3bmPvvv0AjO3Zy7o7twH4y6oZZ3/U0fBS1Qxbv3HHU7+kE/bu28/6jTv6VJHmM/ujjobBMcN279nbql3qJfujjobBMcNOX7SwVbvUS/ZHHQ2DY4atXb2ShQuGDmhbuGCItatX9qkizWf2Rx0NB8dn2MSAo3exaDawP+pozItXx46MjJQPOZSkdpLcW1Ujk9t7eqkqyZokO5LsTHLtFMvPSvLxJFuTfDLJ0qb9nCT3JNneLHtV1zY3J/lSki3N55xeHoMk6UA9C44kQ8ANwMuBVcDlSVZNWu0dwPuq6keB64G3Ne3fAl5bVc8F1gDvTLKoa7u1VXVO89nSq2OQJB2sl2cc5wE7q+qhqnoCuA24eNI6q4BPNNN3Tyyvqs9X1Rea6d3A14GDXiYiSZp5vQyOJcDDXfO7mrZu9wGXNtM/Bzwjyfd1r5DkPOBE4Itdzb/fXML6oyQnTfUPT3JlktEko+Pj48dyHJKkLv2+HffXgJck2Qy8BBgDnvoaa5LTgPcD/6mqvtM0rwOeDTwfeBbwG1PtuKpurKqRqhoZHvZkRZKOl17ejjsGnNE1v7Rpe0pzGepSgCTfC7yiqvY086cAfw38ZlV9tmubR5rJbyd5L53wkSTNkF6ecWwCViRZnuRE4DJgQ/cKSRYnmahhHXBT034i8EE6A+d3TNrmtOZngEuA+3t4DJKkSXoWHFX1JHAVsBF4ELi9qrYnuT7JRc1qLwV2JPk88APA7zftrwReDLx+ittub0myDdgGLAZ+r1fHIEk6mF8AlCRNqS9fAJQkzT0GhySpFYNDktSKwSFJasXgkCS1YnBIkloxOCRJrRgckqRWDA5JUisGhySpFYNDktSKwSFJaqWX7+OQZpW7No+xfuMOdu/Zy+mLFrJ29UouOXfySymlmTHI/dHg0Lxw1+Yx1t25jb37Oi+YHNuzl3V3bgMYmF9WzR2D3h+9VKV5Yf3GHU/9kk7Yu28/6zfu6FNFms8GvT8aHJoXdu/Z26pd6qVB748Gh+aF0xctbNUu9dKg90eDQ/PC2tUrWbhg6IC2hQuGWLt6ZZ8q0nw26P3RwXHNCxMDjoN6F4vmlkHvj75zXJI0pb68czzJmiQ7kuxMcu0Uy89K8vEkW5N8MsnSrmWvS/KF5vO6rvYfT7Kt2ecfJ0kvj0GSdKCeBUeSIeAG4OXAKuDyJKsmrfYO4H1V9aPA9cDbmm2fBfwO8BPAecDvJHlms827gTcCK5rPml4dgyTpYL084zgP2FlVD1XVE8BtwMWT1lkFfKKZvrtr+WrgY1X1aFX9I/AxYE2S04BTquqz1bnG9j7gkh4egyRpkl4GxxLg4a75XU1bt/uAS5vpnwOekeT7DrPtkmb6cPsEIMmVSUaTjI6Pjx/1QUiSDtTv23F/DXhJks3AS4AxYP/hN5meqrqxqkaqamR4ePh47FKSRG9vxx0DzuiaX9q0PaWqdtOccST5XuAVVbUnyRjw0knbfrLZfumk9gP2KUnqrV6ecWwCViRZnuRE4DJgQ/cKSRYnmahhHXBTM70R+Nkkz2wGxX8W2FhVjwCPJXlBczfVa4EP9fAYJEmT9OyMo6qeTHIVnRAYAm6qqu1JrgdGq2oDnbOKtyUp4NPALzXbPprkv9IJH4Drq+rRZvoXgZuBhcBHmo/Ud4P8mGzNLb3ui34BUDoOJj8mGzqPkHjbpWcbHppRx7Mv9uULgNJ8MeiPydbcMRN90eCQjoNBf0y25o6Z6IsGh3QcDPpjsjV3zERfNDik42DQH5OtuWMm+qKPVZeOg0F/TLbmjpnoi95VJUmakndVSZKOC4NDktSKwSFJasXgkCS1YnBIkloxOCRJrRgckqRWDA5JUisGhySpFYNDktSKwSFJasXgkCS1YnBIkloxOCRJrfQ0OJKsSbIjyc4k106x/MwkdyfZnGRrkgua9iuSbOn6fCfJOc2yTzb7nFj2/b08BknSgXr2IqckQ8ANwMuAXcCmJBuq6oGu1a4Dbq+qdydZBXwYWFZVtwC3NPs5G7irqrZ0bXdFVfmCDUnqg16ecZwH7Kyqh6rqCeA24OJJ6xRwSjN9KrB7iv1c3mwrSZoFehkcS4CHu+Z3NW3d3gq8OskuOmcbV0+xn1cBt05qe29zmeq3kuQ41StJmoZ+D45fDtxcVUuBC4D3J3mqpiQ/AXyrqu7v2uaKqjob+Knm85qpdpzkyiSjSUbHx8d7dwSSNM/0MjjGgDO65pc2bd3eANwOUFX3ACcDi7uWX8aks42qGmt+Pg58gM4lsYNU1Y1VNVJVI8PDw8dwGJKkbr0Mjk3AiiTLk5xIJwQ2TFrnq8D5AEmeQyc4xpv5pwGvpGt8I8kJSRY30wuAC4H7kSTNmJ7dVVVVTya5CtgIDAE3VdX2JNcDo1W1AbgGeE+St9AZKH99VVWzixcDD1fVQ127PQnY2ITGEPC3wHt6dQySpIPlu3+n566RkZEaHfXuXUlqI8m9VTUyub3fg+OSpAFjcEiSWjE4JEmtGBySpFYMDklSKwaHJKkVg0OS1IrBIUlqxeCQJLVicEiSWjE4JEmtGBySpFYMDklSKwaHJKkVg0OS1IrBIUlqpWdvAJSOxl2bx1i/cQe79+zl9EULWbt6JZecu6TfZWmesj9OzeCYgwa1s9+1eYx1d25j7779AIzt2cu6O7cBDET9mpr9ce7xUtUcM9HZx/bspfhuZ79r81i/Szui9Rt3PPVLOmHvvv2s37ijTxXpWNkf56ZpBUeSpyd5WjP9w0kuSrKgt6XpaAxyZ9+9Z2+rds1+9se5abpnHJ8GTk6yBPgo8Brg5l4VpaM3yJ399EULW7Vr9rM/zk3TDY5U1beAS4F3VdV/AJ57xI2SNUl2JNmZ5Noplp+Z5O4km5NsTXJB074syd4kW5rPn3Rt8+NJtjX7/OMkmeYxzAuD3NnXrl7JwgVDB7QtXDDE2tUr+1SRjpX9cW6adnAkeSFwBfDXTdvQYdYnyRBwA/ByYBVweZJVk1a7Dri9qs4FLgPe1bXsi1V1TvN5U1f7u4E3Aiuaz5ppHsO8MMid/ZJzl/C2S89myaKFBFiyaCFvu/TseT8QOcjsj3PTdO+qejOwDvhgVW1P8oPA3UfY5jxgZ1U9BJDkNuBi4IGudQo4pZk+Fdh9uB0mOQ04pao+28y/D7gE+Mg0j2POm+jUg3gXC3TqH5RadWT2x7lpWsFRVZ8CPgXQDJJ/o6p++QibLQEe7prfBfzEpHXeCnw0ydXA04Gf6Vq2PMlm4DHguqr6TLPPXZP2OeV/1SRXAlcCnHnmmUcodW6xs2s2sT/OPdO9q+oDSU5J8nTgfuCBJGuPwz//cuDmqloKXAC8vwmmR4Azm0tYvwp8IMkph9nPQarqxqoaqaqR4eHh41CqJAmmP8axqqoe47uXhZbTubPqcMaAM7rmlzZt3d4A3A5QVfcAJwOLq+rbVfX/mvZ7gS8CP9xsv/QI+5Qk9dB0g2NB872NS4ANVbWPzvjE4WwCViRZnuREOoPfGyat81XgfIAkz6ETHONJhpvBdZrxlBXAQ1X1CPBYkhc0d1O9FvjQNI9BknQcTDc4/hfwZTrjEJ9OchadsYdDqqongauAjcCDdO6e2p7k+iQXNatdA7wxyX3ArcDrq6qAFwNbk2wB7gDeVFWPNtv8IvCnwE46ZyIOjEvSDErn7/RRbJic0ITDrDcyMlKjo6P9LkOSBkqSe6tqZHL7dAfHT03yh0lGm89/p3P2IUmaZ6Z7qeom4HHglc3nMeC9vSpKkjR7TfcLgP+qql7RNf+7zfiDJGmeme4Zx94kPzkxk+RFwOx/Spkk6bib7hnHm4D3JTm1mf9H4HW9KUmSNJtN95Ej9wHPm/j2dlU9luTNwNZeFidJmn1avQGwqh5rvkEOnUeBSJLmmWN55/icfg/GoL4nWXOT/VGzybEEx9F9c3AA+JJ6zSb2R802h71UleTxJI9N8XkcOH2Gapxxg/yeZM099kfNNoc946iqZ8xUIbPJIL8nWXOP/VGzTavB8flikN+TrLnH/qjZxuCYwiC/J1lzj/1Rs82xDI7PWYP+nmTNLfZHzTZH/Vj1QeJj1SWpvWN6rLokSRMMDklSKwaHJKkVg0OS1IrBIUlqpafBkWRNkh1Jdia5dorlZya5O8nmJFuTXNC0vyzJvUm2NT9/umubTzb73NJ8vr+XxyBJOlDPvseRZAi4AXgZsAvYlGRDVT3Qtdp1wO1V9e4kq4APA8uAbwD/rqp2J/kRYCPQfdP6FVXl/bWS1Ae9POM4D9hZVQ9V1RPAbcDFk9Yp4JRm+lRgN0BVba6q3U37dmBhkpN6WKskaZp6GRxLgIe75ndx4FkDwFuBVyfZReds4+op9vMK4HNV9e2utvc2l6l+K8mU7wVJcmWS0SSj4+PjR30QkqQD9Xtw/HLg5qpaClwAvD/JUzUleS7wB8AvdG1zRVWdDfxU83nNVDuuqhuraqSqRoaHh3t2AJI03/QyOMaAM7rmlzZt3d4A3A5QVfcAJwOLAZIsBT4IvLaqvjixQVWNNT8fBz5A55KYJGmG9DI4NgErkixPciJwGbBh0jpfBc4HSPIcOsExnmQR8NfAtVX1dxMrJzkhyUSwLAAuBO7v4TFIkibpWXBU1ZPAVXTuiHqQzt1T25Ncn+SiZrVrgDcmuQ+4FXh9dZ66eBXwQ8BvT7rt9iRgY5KtwBY6ZzDv6dUxSJIO5tNxJUlT8um4kqTjwuCQJLVicEiSWjE4JEmtGBySpFYMDklSKwaHJKkVg0OS1IrBIUlqxeCQJLVicEiSWjE4JEmtGBySpFYMDklSKwaHJKkVg0OS1IrBIUlqxeCQJLVicEiSWjE4JEmtGBySpFZ6GhxJ1iTZkWRnkmunWH5mkruTbE6yNckFXcvWNdvtSLJ6uvuUJPVWz4IjyRBwA/ByYBVweZJVk1a7Dri9qs4FLgPe1Wy7qpl/LrAGeFeSoWnuU5LUQ7084zgP2FlVD1XVE8BtwMWT1inglGb6VGB3M30xcFtVfbuqvgTsbPY3nX1Kknqol8GxBHi4a35X09btrcCrk+wCPgxcfYRtp7NPAJJcmWQ0yej4+PjRHoMkaZJ+D45fDtxcVUuBC4D3JzkuNVXVjVU1UlUjw8PDx2OXkiTghB7ueww4o2t+adPW7Q10xjCoqnuSnAwsPsK2R9qnJKmHennGsQlYkWR5khPpDHZvmLTOV4HzAZI8BzgZGG/WuyzJSUmWAyuAv5/mPiVJPdSzM46qejLJVcBGYAi4qaq2J7keGK2qDcA1wHuSvIXOQPnrq6qA7UluBx4AngR+qar2A0y1z14dgyTpYOn8nZ7bRkZGanR0tN9lSNJASXJvVY1Mbu/34LgkacAYHJKkVgwOSVIrBockqRWDQ5LUisEhSWrF4JAktWJwSJJaMTgkSa0YHJKkVgwOSVIrBockqRWDQ5LUisEhSWrF4JAktWJwSJJaMTgkSa0YHJKkVgwOSVIrBockqZWeBkeSNUl2JNmZ5Noplv9Rki3N5/NJ9jTt/6arfUuSf0lySbPs5iRf6lp2Ti+PQZJ0oBN6teMkQ8ANwMuAXcCmJBuq6oGJdarqLV3rXw2c27TfDZzTtD8L2Al8tGv3a6vqjl7VLkk6tF6ecZwH7Kyqh6rqCeA24OLDrH85cOsU7f8e+EhVfasHNUqSWuplcCwBHu6a39W0HSTJWcBy4BNTLL6MgwPl95NsbS51nXSIfV6ZZDTJ6Pj4ePvqJUlTmi2D45cBd1TV/u7GJKcBZwMbu5rXAc8Gng88C/iNqXZYVTdW1UhVjQwPD/emakmah3oZHGPAGV3zS5u2qUx1VgHwSuCDVbVvoqGqHqmObwPvpXNJTJI0Q3oZHJuAFUmWJzmRTjhsmLxSkmcDzwTumWIfB417NGchJAlwCXD/ca5bknQYPburqqqeTHIVnctMQ8BNVbU9yfXAaFVNhMhlwG1VVd3bJ1lG54zlU5N2fUuSYSDAFuBNvToGSdLBMunv9Zw0MjJSo6Oj/S5DkgZKknuramRy+2wZHJckDQiDQ5LUisEhSWrF4JAktWJwSJJa6dntuJqb7to8xvqNO9i9Zy+nL1rI2tUrueTcKZ8kI/Wc/bE/DA5N212bx1h35zb27us8GWZsz17W3bkNwF9WzTj7Y/94qUrTtn7jjqd+SSfs3bef9Rt39KkizWf2x/4xODRtu/fsbdUu9ZL9sX8MDk3b6YsWtmqXesn+2D8Gh6Zt7eqVLFwwdEDbwgVDrF29sk8VaT6zP/aPg+OatokBR+9i0Wxgf+wfH3IoSZqSDzmUJB0XBockqRWDQ5LUisEhSWrF4JAktTIv7qpKMg585Sg3Xwx84ziWM5OsvT8GtfZBrRusvVfOqqrhyY3zIjiORZLRqW5HGwTW3h+DWvug1g3WPtO8VCVJasXgkCS1YnAc2Y39LuAYWHt/DGrtg1o3WPuMcoxDktSKZxySpFYMDklSKwbHYSRZk2RHkp1Jru13PdOR5Iwkdyd5IMn2JL/S75raSjKUZHOSv+p3LW0kWZTkjiT/N8mDSV7Y75qmK8lbmv5yf5Jbk5zc75oOJclNSb6e5P6utmcl+ViSLzQ/n9nPGg/lELWvb/rM1iQfTLKonzVOh8FxCEmGgBuAlwOrgMuTrOpvVdPyJHBNVa0CXgD80oDU3e1XgAf7XcRR+B/A31TVs4HnMSDHkGQJ8MvASFX9CDAEXNbfqg7rZmDNpLZrgY9X1Qrg4838bHQzB9f+MeBHqupHgc8D62a6qLYMjkM7D9hZVQ9V1RPAbcDFfa7piKrqkar6XDP9OJ0/XgPzZpskS4F/C/xpv2tpI8mpwIuBPwOoqieqak9/q2rlBGBhkhOA7wF297meQ6qqTwOPTmq+GPjzZvrPgUtmtKhpmqr2qvpoVT3ZzH4WWDrjhbVkcBzaEuDhrvldDNAfYIAky4Bzgf/T30paeSfw68B3+l1IS8uBceC9zWW2P03y9H4XNR1VNQa8A/gq8Ajwzar6aH+rau0HquqRZvprwA/0s5hj8PPAR/pdxJEYHHNUku8F/hJ4c1U91u96piPJhcDXq+reftdyFE4Afgx4d1WdC/wzs/dyyQGa8YCL6YTf6cDTk7y6v1Udvep8x2DgvmeQ5DfpXGq+pd+1HInBcWhjwBld80ubtlkvyQI6oXFLVd3Z73paeBFwUZIv07k0+NNJ/qK/JU3bLmBXVU2c3d1BJ0gGwc8AX6qq8araB9wJ/Os+19TWPyQ5DaD5+fU+19NKktcDFwJX1AB8uc7gOLRNwIoky5OcSGewcEOfazqiJKFznf3BqvrDftfTRlWtq6qlVbWMzr/vT1TVQPyfb1V9DXg4ycqm6XzggT6W1MZXgRck+Z6m/5zPgAzsd9kAvK6Zfh3woT7W0kqSNXQuz15UVd/qdz3TYXAcQjNYdRWwkc4v0e1Vtb2/VU3Li4DX0Pm/9S3N54J+FzVPXA3ckmQrcA7w3/pcz7Q0Z0l3AJ8DttH5uzBrH4OR5FbgHmBlkl1J3gC8HXhZki/QOYN6ez9rPJRD1P4/gWcAH2t+X/+kr0VOg48ckSS14hmHJKkVg0OS1IrBIUlqxeCQJLVicEiSWjE4pCNI8k/Nz2VJ/uNx3vd/mTT/v4/n/qVeMDik6VsGtAqO5qGBh3NAcFTVoH1jW/OQwSFN39uBn2q+pPWW5r0h65Nsat6l8AsASV6a5DNJNtB8ezzJXUnubd55cWXT9nY6T6TdkuSWpm3i7CbNvu9Psi3Jq7r2/cmu937c0nzbmyRvb97DsjXJO2b8347mjSP935Ck77oW+LWquhCgCYBvVtXzk5wE/F2SiafK/hiddyx8qZn/+ap6NMlCYFOSv6yqa5NcVVXnTPHPupTOt8+fByxutvl0s+xc4Ll0Hn3+d8CLkjwI/Bzw7KqqQXgZkAaXZxzS0ftZ4LVJttB5dP33ASuaZX/fFRoAv5zkPjrvWzija71D+Ung1qraX1X/AHwKeH7XvndV1XeALXQuoX0T+Bfgz5JcCgzEM480mAwO6egFuLqqzmk+y7veY/HPT62UvJTO85NeWFXPAzYDx/Jq1m93Te8HTmierXYenWdOXQj8zTHsXzosg0OavsfpPIxuwkbgPzePsSfJDx/i5U2nAv9YVd9K8mw6r/SdsG9i+0k+A7yqGUcZpvN2wb8/VGHN+1dOraoPA2+hc4lL6gnHOKTp2wrsby453UznHePLgM81A9TjTP3K0r8B3tSMQ+ygc7lqwo3A1iSfq6oruto/CLwQuI/OS4l+vaq+1gTPVJ4BfCjJyXTOhH716A5ROjKfjitJasVLVZKkVgwOSVIrBockqRWDQ5LUisEhSWrF4JAktWJwSJJa+f8/uZ4ySCKPjAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}